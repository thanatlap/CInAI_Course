{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab3 - Introduction to Deep Neural Network\n",
    "- Name1, Student's ID1\n",
    "- Name2, Student's ID2\n",
    "\n",
    "Name your file to 58_34xx_34xx.ipynb\n",
    "\n",
    "## Lab Instruction \n",
    "\n",
    "In this lab, you will learn to create a simple fully-connect neural network using Keras library with Tensorflow backend. We will play with MNIST data which is a Keras build-in dataset. \n",
    "\n",
    "See http://yann.lecun.com/exdb/mnist\n",
    "\n",
    "First, import all the library that we will use in this lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "### Load Data ###\n",
    "\n",
    "#################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Learn About the Data\n",
    "\n",
    "Understand your data. For example, its shape, format, datatype, structure, distribution, data classes, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Build Neural Network Model\n",
    "\n",
    "Build a two-layer neural network using `Sequential()`\n",
    "( See https://keras.io/models/sequential ) \n",
    "> INPUT -> LINEAR -> RELU -> LINEAR -> SIGMOID\n",
    "\n",
    "with the hidden layer of size 512\n",
    "\n",
    "See Keras Model: https://keras.io/models/about-keras-models/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile your model with the following argument.\n",
    "\n",
    "```\n",
    "optimizer='sgd',\n",
    "loss='categorical_crossentropy',\n",
    "metrics=['accuracy']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how our model looklike using `.summary()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Preprocessing\n",
    "\n",
    "- Reshape the features data (flattern) and normalize the value to be between 0 and 1\n",
    "- One-hot the target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model Training \n",
    "\n",
    "Use `.fit()` to train your neural network model and return the record of accuracy and loss value in each epoch\n",
    "\n",
    "We will train model with 10 epoch (If you confident with your computer performance, you can trian model with more epoch.)\n",
    "\n",
    "We will train with mini-batch method with each the batch size equal to 128 data.\n",
    "\n",
    "To prevent the overfit with test set, we will split a current training data into 90% for training and 10% for validating model.\n",
    "\n",
    "This process will take about a minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will plot the loss and accuracy of both train set and validate set over iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  matplotlib.pyplot  as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function argument is a record or history of the model during training process.\n",
    "def plot_loss_fn(history):\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "def plot_acc_fn(history):\n",
    "\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    \n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At which iteration does your model start to get overfit? give your reason.\n",
    "\n",
    "**ANSWER**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Model Evaluation\n",
    "\n",
    "Evaluate your model with test set using `.evaluate()` and compare the result with the training set and validate set. Does your model overfit or underfit? How about the bias and variance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use confusion matrix to analyse the performance of your model. which class does your model classify poorly. What is your model precision and recall. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "### evaluate your model ###\n",
    "\n",
    "###########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**ANSWER**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Model tuning\n",
    "\n",
    "Try to tune your model by: \n",
    "1. Adjust the learning rate of your optimizer by increasing and decreasing learning rate and see how it affect your model. See https://keras.io/optimizers\n",
    "2. Increasing and decreasing a epoch and see how it affect your model.\n",
    "3. Increasing and decreasing a batch size and see how it affect your model.\n",
    "3. Change your the model structure by adding more hidden layer with any number of node and see how it affect your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Discussion and Result\n",
    "Write down your analysis from previous step\n",
    "\n",
    "**ANSWER**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
