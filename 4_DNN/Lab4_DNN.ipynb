{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab4 - Training Deep Neural Network\n",
    "- Name1, Student's ID1\n",
    "- Name2, Student's ID2\n",
    "\n",
    "Name your file to 58_34xx_34xx.ipynb\n",
    "\n",
    "## Lab Instruction \n",
    "\n",
    "In this lab, you will learn to train a deep fully-connect neural network using Keras library with Tensorflow backend. We will use MNIST data which is a Keras build-in dataset. \n",
    "\n",
    "See http://yann.lecun.com/exdb/mnist\n",
    "\n",
    "**Note:**\n",
    "Before doing any machine learning/deep learning project, you have to think about the following thing:\n",
    "1. What is your problem and your data?\n",
    "- What type of problem do you want to solve? What is your data? What are you trying to predict? Does your data have enough information for your model to predict the expected output?\n",
    "\n",
    "2. How do you measure your success?\n",
    "- What do you mean by good model performance? How do you know that your model is ready to be deploy?\n",
    "- Accuracy? Precision and recall? profit gain? ROC AUC?\n",
    "\n",
    "3. What is your evaluation method?\n",
    "- Hold-out method? CV? Iterate CV?\n",
    "\n",
    "4. How to preprocess your data before fed into a model?\n",
    "\n",
    "5. What is your baseline? What is a model structure? how does your last layer look like? What is your loss function? What is your optimization function? \n",
    "\n",
    "6. Develop a overfit model to figure out how big a model you need by\n",
    "6.1 Add more layer\n",
    "6.2 Make layer bigger\n",
    "6.3 Train more epochs\n",
    "\n",
    "7. Tune your model to balance the model performance between underfit and overfit (optimization vs generalization)\n",
    "\n",
    "First, import all important library to this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import mnist\n",
    "\n",
    "### Load data ###\n",
    "\n",
    "#################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn more about the data. For example:\n",
    "- The distribution of a target class. \n",
    "- The characteristic of the input data. How does it looklike? \n",
    "- etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocess a data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a model \n",
    "Using `Sequential()`, build a five-fully connect layer with 128 neuron each, *elu* as an activation function, and *he_initialier* as a weight initialier function. \n",
    "The output is a probability of each target class. We will use *Adam optimizer* with the *cross-entropy loss function*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train the model\n",
    "\n",
    "We will train a total of 10 epoch and a batch size of 128. \n",
    "\n",
    "To prevent an information leak to test set, which casue an overfit, we will split the data to train set, test set, and validation set. Doing so, we will split the training data into 90% train set and 10% validation set.\n",
    "\n",
    "Since keras `validation_split` argument split the last 10% of data to be validation set, the target class may not be equally distributed in validation set. Thus, we have to use `train_test_split`  from sklearn to split the data into train set and validation set. \n",
    "\n",
    "Hint: Use parameter `stratify = y` in `train_test_split()`\n",
    "See http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "### Split data ###\n",
    "\n",
    "##################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fit the model ###\n",
    "\n",
    "#####################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evalute the model\n",
    "\n",
    "Think of the metric that you want to evaluate/measure the performance of your model that can answer the following questions:\n",
    "- The model is overfit or underfit.\n",
    "- At which epoch/iteration that it converge or the model become overfit.\n",
    "- How does the model perform on each data class. What is an overall performace of your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluate the model ###\n",
    "\n",
    "##########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Tune the model \n",
    "\n",
    "Try to tune your model by: \n",
    "1. Try Increasing epoch and see how it affect your model? Does the result better or it get overfit?\n",
    "2. Apply an early stop. What is the result do you get? (See https://chrisalbon.com/deep_learning/keras/neural_network_early_stopping/)\n",
    "4. Try adding regularizer l1 or l2 (or simutaneus l1, l2) to your model. How does it affect your model?\n",
    "5. Try to add dropout (any dropout rate) with every layer. How does it affect your model? Does it help reduce overfit?\n",
    "\n",
    "*Discuss the result from these step in the discssion section*\n",
    "\n",
    "After try above step, **try to achive the highest precision** by tuning the model using what you had aleady learn in the class.\n",
    "You can try to change the structure of the model by increase or decrease the layer and neuron node in each layer. (Use only fully-connect layer, don't use other type of layer yet!)\n",
    "\n",
    "You can also try to do a data augmentation.\n",
    "\n",
    "**The current highest precision of MNIST model is around 99.8%** ( Just try as must as possible, don't worry if you don't achieve this number of precision.)\n",
    "\n",
    "**Write  down what are you doing and why in each tuning step**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Final Evaluation\n",
    "\n",
    "After you make sure that your model is good enough to be deploy in application, it is a time to evaluate your model with test set in order to test that your model is generalize well and not overfit to validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result & Discussion \n",
    "\n",
    "- Write down the key finding from this lab. Discuss what you had done, what do you get from the output or a result, and why (support your reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Play with your model\n",
    "\n",
    "1. Use any kind of drawing application ( For example, Paint or Adobe Photoshop ), create a 28x28 pixel (any resolution) with black (#000000) background and white (#FFFFFF) paint. \n",
    "2. Draw 3 any distinct single digit number of a range from 0 - 9. Then save the image (PNG)\n",
    "3. Install open-cv (See https://pypi.org/project/opencv-python) by \n",
    "> `pip install opencv-python` <br/> or conda (See https://anaconda.org/conda-forge/opencv)\n",
    "4. Load your image to this IPython using ```imread()``` function\n",
    "5. Preprocess as what you did during the development stage.\n",
    "6. Feed your image to your best model.\n",
    "\n",
    "What class do your model predict? Does it correct? If not, why do it still get negative result since your model get more than 90% accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenges: Play with initializer\n",
    "\n",
    "- Create two-layer neural network with any hyperparameter\n",
    "- Use or create an weight initializer function that initialize all the weight to one. See: https://keras.io/initializers/\n",
    "- Discuss the result. what happen? and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
