{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab5 - Training Deep Convolutional Neural Network\n",
    "- Name1, Student's ID1\n",
    "- Name2, Student's ID2\n",
    "- Name3, Student's ID3\n",
    "\n",
    "Name your file to (first 2 student ID digit)_(last 4 student ID digit)*4.ipynb\n",
    "\n",
    "## Lab Instruction \n",
    "\n",
    "In this lab, you will learn to train a deep convolutional neural network using Keras library with Tensorflow backend. We will use MNIST and Cat vs Dog dataset.\n",
    "\n",
    "See http://yann.lecun.com/exdb/mnist <br>\n",
    "See https://www.kaggle.com/c/dogs-vs-cats/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import callbacks\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load _utils\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from keras import backend as K\n",
    "\n",
    "# Test\n",
    "def print_hello():\n",
    "    print('Hello')\n",
    "\n",
    "# define a function to plot the result from training step\n",
    "def show_result(history): \n",
    "    \n",
    "    # Print the result from the last epoch\n",
    "    print('Last train accuracy: %s'%history.history['acc'][-1])\n",
    "    print('Last validation accuracy: %s'%history.history['val_acc'][-1])\n",
    "    \n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    \n",
    "    epochs = range(1, len(loss) + 1)   \n",
    "    \n",
    "    # Define a subplot \n",
    "    fig, axs = plt.subplots(1,2,figsize=(15,4))\n",
    "    \n",
    "    # Plot loss\n",
    "    loss_plot = axs[0]\n",
    "    \n",
    "    loss_plot.plot(epochs, loss, 'c--', label='Training loss')\n",
    "    loss_plot.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    loss_plot.set_title('Training and validation loss')\n",
    "    loss_plot.set_xlabel('Epochs')\n",
    "    loss_plot.set_ylabel('Loss')\n",
    "    loss_plot.legend()\n",
    "    \n",
    "    # Plot accuracy\n",
    "    acc_plot = axs[1]\n",
    "    \n",
    "    acc_plot.plot(epochs, acc, 'c--', label='Training acc')\n",
    "    acc_plot.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    acc_plot.set_title('Training and validation accuracy')\n",
    "    acc_plot.set_xlabel('Epochs')\n",
    "    acc_plot.set_ylabel('Accuracy')\n",
    "    acc_plot.legend()\n",
    "\n",
    "# Define an evaluation function to print the evaluation result\n",
    "def evaluation_report(model,features,labels):\n",
    "    \n",
    "    # Calculate result\n",
    "    result = model.evaluate(features,labels,verbose=False)\n",
    "    \n",
    "    # Predict and convert into a class\n",
    "    pred_class = model.predict(features).argmax(axis=1)\n",
    "    \n",
    "    # Show report\n",
    "    print(confusion_matrix(labels,pred_class))\n",
    "    print(classification_report(labels,pred_class))\n",
    "    print(\"Loss: %s Accuracy: %s\" %(result[0],result[1]))\n",
    "    \n",
    "    return pred_class\n",
    "\n",
    "\n",
    "# Show a subplot of the incorrect predict data\n",
    "def show_false_prediction(predict, feature, label, img_size=28, channel=1):\n",
    "\n",
    "    false_pred = feature[(predict != label).tolist()]\n",
    "    actual_label = label[(predict != label).tolist()]\n",
    "    false_label = predict[(predict != label).tolist()]\n",
    "    if channel == 3:\n",
    "        false_pred = false_pred.reshape(false_pred.shape[0],img_size,img_size,channel)\n",
    "    elif channel == 1:\n",
    "        false_pred = false_pred.reshape(false_pred.shape[0],img_size,img_size)\n",
    "    else:\n",
    "        raise ValueError('Must be RGB or gray scale image')\n",
    "    \n",
    "    print(false_pred.shape)\n",
    "\n",
    "    fig, ax = plt.subplots(3,10,figsize=(15,6))\n",
    "    fig.suptitle('The incorrect prediction')\n",
    "\n",
    "    for i in range(3):\n",
    "        for j in range(10):\n",
    "            ax[i,j].imshow(false_pred[j + i*10],cmap='gray')\n",
    "            ax[i,j].set_title('Pred %s Act %s'%(false_label[j + i*10],actual_label[j + i*10]))\n",
    "            \n",
    "# Show activation value of each layer\n",
    "def show_layer_activation(activation, model,num_layer,num_row=16):\n",
    "    layer_names = []\n",
    "    for layer in model.layers[:num_layer]:\n",
    "        layer_names.append(layer.name)\n",
    "\n",
    "    images_per_row = num_row\n",
    "    for layer_name, layer_activation in zip(layer_names,activation):\n",
    "        n_features = layer_activation.shape[-1]\n",
    "\n",
    "        size = layer_activation.shape[1]\n",
    "\n",
    "        n_cols = n_features//images_per_row\n",
    "        display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
    "\n",
    "        for col in range(n_cols):\n",
    "            for row in range(images_per_row):\n",
    "                channel_image = layer_activation[0,:,:,col*images_per_row + row]\n",
    "                channel_image -= channel_image.mean()\n",
    "                channel_image /= channel_image.std()\n",
    "                channel_image *= 64\n",
    "                channel_image += 128\n",
    "                channel_image = np.clip(channel_image, 0,255).astype('uint8')\n",
    "                display_grid[col*size:(col +1)*size,\n",
    "                             row*size:(row+1)*size] = channel_image\n",
    "        scale = 1./size\n",
    "        plt.figure(figsize=(scale*display_grid.shape[1],\n",
    "                           scale*display_grid.shape[0]))\n",
    "        plt.title(layer_name)\n",
    "        plt.grid(False)\n",
    "        plt.imshow(display_grid, aspect='auto', cmap='viridis')\n",
    "        \n",
    "        \n",
    "def deprocess_image(img):\n",
    "    \n",
    "    # Zero-centering and make sure that std is 0.1\n",
    "    img -= img.mean()\n",
    "    img /= (img.std() + 1e-5)\n",
    "    img *= 0.1\n",
    "    \n",
    "    # Clips to [0,1]\n",
    "    img += 0.5\n",
    "    img = np.clip(img,0,1)\n",
    "    \n",
    "    # Convert to RGB array\n",
    "    img *= 255\n",
    "    img = np.clip(img,0,255).astype('uint8')\n",
    "    \n",
    "    return img\n",
    "\n",
    "def generate_pattern(model, layer_name , filter_index, size=150):\n",
    "    # Build the loss function that maximize the activation of the nth filter of the layer under consideration\n",
    "    layer_output = model.get_layer(layer_name).output\n",
    "    loss = K.mean(layer_output[:,:,:,filter_index])\n",
    "    \n",
    "    # Compute the gradient of the input picture with regard to this loss\n",
    "    grads = K.gradients(loss, model.input)[0]\n",
    "    \n",
    "    # Normalize the gradient\n",
    "    grads /= (K.sqrt(K.mean(K.square(grads))) +1e-5)\n",
    "    \n",
    "    # Return the loss and gradient given the input picture\n",
    "    iterate = K.function([model.input],[loss, grads])\n",
    "    \n",
    "    # Stars from a gray image with some noise\n",
    "    input_img_data = np.random.random((1, size, size, 3)) * 20 + 128.\n",
    "    \n",
    "    # Run gradient ascent for 40 step\n",
    "    step = 1.\n",
    "    for i in range(40):\n",
    "        loss_value, grads_value = iterate([input_img_data])\n",
    "        input_img_data += grads_value * step\n",
    "        \n",
    "    img = input_img_data[0]\n",
    "    return deprocess_image(img)\n",
    "\n",
    "### feed layer name. ie, 'conv_1'\n",
    "def visualize_filter(model,layer_name, size= 64, margin = 5):\n",
    "\n",
    "    # Empty black image to store results\n",
    "    results = np.zeros((8 * size + 7 * margin, 8 * size + 7 * margin, 3))\n",
    "\n",
    "    # iterate over the row of result grid\n",
    "    for i in range(8):\n",
    "        # Iterate over the column of the result grid\n",
    "        for j in range(8):\n",
    "            # Generates the pattern for filter i + (j*8) in layer_name\n",
    "            filter_img = generate_pattern(model, layer_name, i + (j*8), size=size)\n",
    "            \n",
    "            # Puts the result in the square (i,j) of the results grid\n",
    "            horizontal_start = i * size + i * margin\n",
    "            horizontal_end = horizontal_start + size\n",
    "            vertical_start = j * size + j * margin\n",
    "            vertical_end = vertical_start + size\n",
    "            results[horizontal_start:horizontal_end,\n",
    "                    vertical_start:vertical_end, :] = filter_img\n",
    "\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.imshow(results)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load MNIST dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load dataset ###\n",
    "\n",
    "####################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocess data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    data = data.reshape(data.shape[0],data.shape[1],data.shape[2],1)\n",
    "    data = data.astype('float32')/255.\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a convolutional neural network \n",
    "Try to build a network that have a same or out perform our previous fully-connect model. (You can use any technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = models.Sequential()\n",
    "cnn.add(layers.Conv2D(filters=32,\n",
    "                      kernel_size=3,\n",
    "                      padding='same',\n",
    "                      activation = 'elu',\n",
    "                      kernel_initializer='he_normal',\n",
    "                      input_shape=(IMG_WIDTH,IMG_HEIGHT,CHANNEL,),\n",
    "                      name = 'conv_1',\n",
    "                     ))\n",
    "cnn.add(layers.MaxPooling2D(2,2,name='max_pool_1'))\n",
    "cnn.add(layers.Conv2D(filters=64,\n",
    "                      kernel_size=3,\n",
    "                      padding='same',\n",
    "                      kernel_initializer='he_normal',\n",
    "                      activation = 'elu',\n",
    "                      name = 'conv_3',\n",
    "                     ))\n",
    "cnn.add(layers.MaxPooling2D(2,2,name='max_pool_2'))\n",
    "cnn.add(layers.Dropout(0.25,name='dropout_1'))\n",
    "cnn.add(layers.Flatten())\n",
    "cnn.add(layers.Dense(256,activation='elu',\n",
    "                     kernel_initializer='he_normal',\n",
    "                     name='fully_connect_1'\n",
    "                    ))\n",
    "cnn.add(layers.Dropout(0.5,name='dropout_2'))\n",
    "cnn.add(layers.Dense(10,activation='softmax',\n",
    "                     kernel_initializer='he_normal',\n",
    "                     name='output'\n",
    "                    ))\n",
    "cnn.compile(optimizer='adam',\n",
    "           loss = 'sparse_categorical_crossentropy',\n",
    "           metrics=['acc'])\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Trainig CNN Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split train and validation data ###\n",
    "\n",
    "#######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train model ###\n",
    "\n",
    "###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_result(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluate your model \n",
    "#### 5.1 Show the confusion matrix and classification report\n",
    "Using function ```evaluation_report(model,feature,label)``` define above to print the classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Show which image that your model incorrectly predict\n",
    "\n",
    "Using function ```show_false_prediction(pred_class, actual_feature, actual_label)``` that is define above to show which image that your model predict wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discuss the results**\n",
    "\n",
    "*Discussion*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Data Augmentation \n",
    "\n",
    "Using the ```ImageDataGenerator``` module to generate more data. This technique is called data augmentation. It help generate more variation of the data which help prevent overfit and generalize better.\n",
    "\n",
    "Lookup in the Keras document to see what method does it provide. https://keras.io/preprocessing/image\n",
    "\n",
    "Becasue we want to build a data generator object, we have to re-load the data and specify rescale argument in ImageDataGenerator module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-load the image data\n",
    "(X_train,y_train), (X_test,y_test) = mnist.load_data()\n",
    "\n",
    "# Because the ImageDataGenerator require tensor of 4 dimension \n",
    "# Reshape data to 4 dimension (batch, width, height, channel)\n",
    "def reshape_gray(data):\n",
    "    data = data.reshape(data.shape[0],data.shape[1],data.shape[2],1)\n",
    "    return data\n",
    "\n",
    "X_train = reshape_gray(X_train)\n",
    "X_test = reshape_gray(X_test)\n",
    "\n",
    "# split to validation set and train set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train,test_size=0.1,random_state=0,stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update global variable\n",
    "IMG_WIDTH = X_train.shape[1]\n",
    "IMG_HEIGHT = X_train.shape[2]\n",
    "CHANNEL = X_train.shape[3]\n",
    "\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a generator for train set and test set\n",
    "\n",
    "train_datagen = image.ImageDataGenerator(rescale=1./255,\n",
    "                                  rotation_range=40,\n",
    "                                  width_shift_range=0.2,\n",
    "                                  height_shift_range=0.2,\n",
    "                                  shear_range=0.2,\n",
    "                                  zoom_range=0.2,\n",
    "                                  horizontal_flip=False)\n",
    "\n",
    "test_datagen = image.ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Iterator object. \n",
    "train_generator = train_datagen.flow(X_train,y_train,\n",
    "                                    batch_size = BATCH_SIZE,\n",
    "                                    seed=0)\n",
    "\n",
    "validate_generator = test_datagen.flow(X_val,y_val,\n",
    "                                    batch_size = BATCH_SIZE,\n",
    "                                    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Initialize new model using same network structure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Train a model using Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using fit_generator to train your model. We don't need to specify the batch size since we already done that when we create Iterator\n",
    "history = cnn.fit_generator(train_generator, \n",
    "                              epochs=20, \n",
    "                              validation_data=validate_generator)\n",
    "show_result(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4 Evaluate your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_result(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5 Compare the result\n",
    "\n",
    "Compare the result between a model with data augmentation and without data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//discuss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Visualize Layer Activation \n",
    "**Note:** the function is defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an activation model (the model with convolution layer only)\n",
    "\n",
    "num_conv = # Number of convolutional layer in your model (if more than 4, just used 4)\n",
    "layer_outputs = [layer.output for layer in cnn.layers[:num_conv]]\n",
    "activation_model = models.Model(inputs=cnn.input, outputs=layer_outputs)\n",
    "activation_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "# load image to feed into network\n",
    "img = image.load_img('test_data_1.png',target_size=(28,28),grayscale=True)\n",
    "img_tensor = image.img_to_array(img)\n",
    "\n",
    "# Preprocess data\n",
    "img_tensor = np.expand_dims(image.img_to_array(img),axis=0)/255.\n",
    "\n",
    "# Feed into activation model to get an activation value\n",
    "activation = activation_model.predict(img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Feed your model and number of layer you want to show \n",
    "\n",
    "show_layer_activation(activation, model,num_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 What do you think the network can detect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Visualize What The Model See"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Feed your model and layer name, ie. 'conv_1', that you want to show.\n",
    "\n",
    "visualize_filter(model,layer_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 What do you think the network see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Transfer Learning \n",
    "- What is transfer learning https://towardsdatascience.com/transfer-learning-946518f95666\n",
    "- which transfer learning method to use https://medium.com/@14prakash/transfer-learning-using-keras-d804b2e04ef8\n",
    "\n",
    "The following is a tutorial code to load and freeze some layer. Keras also come with a build-in pre-train network on imageNet dataset (See www.image-net.org)\n",
    "\n",
    "Keras Pre-train Network https://keras.io/applications\n",
    "\n",
    "#### 8.1.1 Use Build-in Pre-train Network\n",
    "Keras come with a build-in pre-train network that let you download and use it in your problem. You can import only model structure or import neuron weight that had been train on imageNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import vgg16\n",
    "\n",
    "vgg = vgg16.VGG16(include_top=False, \n",
    "                  weights='imagenet',\n",
    "                  input_shape=(150,150,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.1.2 Use Our Pre-train Network\n",
    "\n",
    "When we are doing the deep learning/machine learning project, sometime, we may encounter a similar problem. After several project, we will have many existing model that we experiment and develop. We can used these model as a pre-train network to solve a new problem. This can save a hugh cost (time and money) and jump start our new project very quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_1 (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pool_1 (MaxPooling2D)    (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_3 (Conv2D)              (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv_4 (Conv2D)              (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pool_2 (MaxPooling2D)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "fully_connect_1 (Dense)      (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 870,634\n",
      "Trainable params: 870,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "prev_cnn = models.load_model('baseline_model_itr40.h5')\n",
    "prev_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use .pop() to remove the last layer\n",
    "# In this case, we want to remove last two layer\n",
    "\n",
    "prev_cnn.pop()\n",
    "prev_cnn.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_1 (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pool_1 (MaxPooling2D)    (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_3 (Conv2D)              (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv_4 (Conv2D)              (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pool_2 (MaxPooling2D)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 64)          0         \n",
      "=================================================================\n",
      "Total params: 870,634\n",
      "Trainable params: 870,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thanatlapthawan/anaconda3/lib/python3.6/site-packages/keras/engine/training.py:478: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    }
   ],
   "source": [
    "# See how our model change\n",
    "prev_cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For both method, if you want to change input size of your network, you have to create a model using functional API.\n",
    "See https://keras.io/models/model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.1 Freezing layer - All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we don't want to train these layer, we have to freeze these layer. \n",
    "# Note that if we want a pre-train as a weight initializer, we don't have to freeze the layer.\n",
    "\n",
    "prev_cnn.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_1 (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pool_1 (MaxPooling2D)    (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_3 (Conv2D)              (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv_4 (Conv2D)              (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pool_2 (MaxPooling2D)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 64)          0         \n",
      "=================================================================\n",
      "Total params: 935,626\n",
      "Trainable params: 870,634\n",
      "Non-trainable params: 64,992\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thanatlapthawan/anaconda3/lib/python3.6/site-packages/keras/engine/training.py:478: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    }
   ],
   "source": [
    "prev_cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.2 Freezing layer - Specific layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze a specific layers\n",
    "# Freeze first 3 layer\n",
    "for i in range(3):\n",
    "    prev_cnn.layers[i].trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3 Connnect your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_1 (Sequential)    (None, 7, 7, 64)          64992     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7, 7, 256)         16640     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 7, 7, 10)          2570      \n",
      "=================================================================\n",
      "Total params: 84,202\n",
      "Trainable params: 19,210\n",
      "Non-trainable params: 64,992\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Time to create a new model\n",
    "new_cnn = models.Sequential()\n",
    "\n",
    "# Add convolutional layer as a pre-train network\n",
    "new_cnn.add(prev_cnn)\n",
    "\n",
    "# Define fully-connect layer\n",
    "new_cnn.add(layers.Dense(256,activation='elu'))\n",
    "new_cnn.add(layers.Dropout(0.2))\n",
    "new_cnn.add(layers.Dense(10,activation='softmax',name='output'))\n",
    "\n",
    "# Show how your network looklike\n",
    "new_cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this process, you can use your network as the way you like. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn! Dog or Cat Application \n",
    "\n",
    "Now, it time to put everything together and develop and Cat vs Dog classifier model. Assume that you and your company want to get more attraction on your product by launching a new product that can classify whether it is a dog or a cat. You have decide that you want a precision more than 90 - 95% in order to launch to product.\n",
    "\n",
    "You have a cat and dog dataset contain total of 25000 images, 12500 for cat and other half for a dog.\n",
    "\n",
    "After successfully develop this model, you can try to play with it to see how it perform. (You can upload your selfies image to see you are a dog or a cat)\n",
    "\n",
    "Some note before start a project:\n",
    "1. You have to load a data into a project using any method (we are not using build-in data anymore!)\n",
    "2. You have to plan on how you will split a data.\n",
    "3. You have to preprocess your data before feed into a network. For example, cropping, padding, etc.\n",
    "4. You can come up with any model or use pre-train model. It depend on you!\n",
    "\n",
    "You have two week for this project so that you can compete with your competitor app! Now, create a new Jupyter notebook and start building a model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
