{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8: Variational Autoencoders\n",
    "\n",
    "Name1, Student's ID1<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Lab Instruction: Generate Random Handwriting Number\n",
    "\n",
    "In this lab, you will learn do the generative model using variational autoencoder to generate random image.</br>\n",
    "\n",
    "This is what we are going to do in this lab: https://www.siarez.com/projects/variational-autoencoder </br>\n",
    "About the variational autoencoder: https://towardsdatascience.com/intuitively-understanding-variational-autoencoders-1bfe67eb5daf\n",
    "\n",
    "This lab, we created model using functional API > https://keras.io/models/model/ \n",
    "\n",
    "### Autoencoder Model\n",
    "\n",
    "![autoencoder](autoencoder.jpg \"Autoencoder\")\n",
    "\n",
    "### Variational Autoencoder Model\n",
    "\n",
    "![VAE](autoencoder.png \"Variational Autoencoder\")\n",
    "\n",
    "### Reconstruct image using Variational Autoencoder Model\n",
    "\n",
    "![variation](variation.png \"Variational Autoencoder\")\n",
    "\n",
    "\n",
    "***Images from:<br>***\n",
    "*1. <a href=https://blog.keras.io/building-autoencoders-in-keras.html> Keras Blog </a></br>*\n",
    "*2. Manning - Deep Learning with Python Book*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "from keras import callbacks\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST data\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data exploration: Shape\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data exploration: Data type\n",
    "x_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min, Max value\n",
    "np.min(x_train),np.max(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape and normalize\n",
    "x_train = x_train.reshape(x_train.shape[0],x_train.shape[1],x_train.shape[2],1)\n",
    "x_train = x_train/255.\n",
    "\n",
    "x_test = x_test.reshape(x_test.shape[0],x_test.shape[1],x_test.shape[2],1)\n",
    "x_test = x_test/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape after preprocess\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train, Test, Validation data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train,y_train,\n",
    "                                                  test_size=0.1,\n",
    "                                                  stratify=y_train,\n",
    "                                                  random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create variational autoencoder model \n",
    "\n",
    "In technical terms, here’s how a VAE works:\n",
    "1. An encoder module turns the input samples input_img into two parameters in a latent space of representations, z_mean and z_log_variance.\n",
    "2. You randomly sample a point z from the latent normal distribution that’s assumed to generate the input image, via\n",
    "> z= z_mean+exp(z_log_variance)* epsilon, *where epsilon is a random tensor of small values.*\n",
    "3. A decoder module maps this point in the latent space back to the original input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variation Parameters\n",
    "z_mean = layers.Dense(latent_dim)(x)\n",
    "z_log_var = layers.Dense(latent_dim)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling distribution funtion\n",
    "\n",
    "def sampling(arg):\n",
    "    z_mean, z_log_var = arg\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0],latent_dim),mean=0., stddev=1.)\n",
    "    return z_mean + K.exp(z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution function sampling layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To define a deconvolution layer\n",
    "> ```layers.Conv2DTranspose( )```\n",
    "\n",
    "See: https://keras.io/layers/convolutional/ Search for ```Conv2DTranspose```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap up encoder model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap up decoder model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warp up VAE model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters of a VAE are trained via two loss functions: \n",
    "1. A reconstruction loss that forces the decoded samples to match the initial inputs.\n",
    "2. A regularization loss (The Kullback-Liebler divergence) that helps learn well-formed latent spaces and reduce overfitting to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom loss function\n",
    "\n",
    "def vae_loss(x, x_decoded_mean):\n",
    "    xent_loss = K.binary_crossentropy(x, x_decoded_mean)\n",
    "    kl_loss = - 0.5 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    return xent_loss + kl_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile and Summarise Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and summarise model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "def viz_loss(history): \n",
    "    \n",
    "    # Print the result from the last epoch\n",
    "    print('Last Training set loss: %s'%history.history['loss'][-1])\n",
    "    print('Last Validation set loss: %s'%history.history['val_loss'][-1])\n",
    "    \n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "    epochs = range(1, len(loss) + 1)   \n",
    "    \n",
    "    plt.plot(epochs, loss, 'c--', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training The VAE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callback for checkpoint \n",
    "checkpoint = callbacks.ModelCheckpoint(filepath='/tmp/weights.hdf5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callback for Tensorboard\n",
    "tensorboard = callbacks.TensorBoard(log_dir='/tmp/logs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To call a Tensorboard, open terminal and type\n",
    ">``` tensorboard --logdir=/full_path_to_your_logs ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting on Test Datast "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct image using test dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show test image\n",
    "\n",
    "x_test_reshape = x_test.reshape(x_test.shape[0],x_test.shape[1],x_test.shape[2])\n",
    "visualize_image(x_test_reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show reconstruct image\n",
    "\n",
    "decoded_imgs = decoded_imgs.reshape(decoded_imgs.shape[0],decoded_imgs.shape[1],decoded_imgs.shape[2])\n",
    "visualize_image(decoded_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Randomly Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly generate a latent vector\n",
    "\n",
    "n = 15\n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "\n",
    "random_input = np.random.uniform(high=2,low=-2,size=(64,latent_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration: X_decode's shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape x_decode\n",
    "decode_digit = x_decoded.reshape(64,digit_size, digit_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Generated Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define visualized image function\n",
    "\n",
    "def visualize_image(image, row=3, col=10, title='Generated hadwriting digit image'):\n",
    "    fig, ax = plt.subplots(row,col,figsize=(13,4))\n",
    "    fig.suptitle(title)\n",
    "    for i in range(row):\n",
    "        for j in range(col):\n",
    "            ax[i,j].imshow(image[j + i*10],cmap='gray')\n",
    "            ax[i,j].get_xaxis().set_visible(False)\n",
    "            ax[i,j].get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show reconstruct image\n",
    "visualize_image(decode_digit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scan The Latent Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a 2D manifold of the digits\n",
    "\n",
    "n = 15  # figure with 15x15 digits\n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "# we will sample n points within [-15, 15] standard deviations\n",
    "grid_x = np.linspace(-15, 15, n)\n",
    "grid_y = np.linspace(-15, 15, n)\n",
    "\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        z_sample = np.array([[xi, yi]]) * 5e-4\n",
    "        x_decoded = decoder.predict(z_sample)\n",
    "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "               j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Latent Space \n",
    "\n",
    "The colored clusters is a type of digit. Close clusters are digits that are structurally similar (i.e. digits that share information in the latent space)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate latent space from test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define latent space visualizatio function\n",
    "\n",
    "def show_latent_space(encoded_imgs):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.scatter(encoded_imgs[:, 0], encoded_imgs[:, 1], \n",
    "                c=y_test,alpha=.7, s=3**2, cmap='viridis')\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show latent space\n",
    "show_latent_space(x_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Optional] To play further with image generation\n",
    "You can try variational autoencoder model with the following dataset: </br>\n",
    "1. Cat & Dog https://www.kaggle.com/c/dogs-vs-cats/data </br>\n",
    "2. Celebrity image (for those who have high computational power) http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html</br>\n",
    "\n",
    "### More on Autoencoder Model\n",
    "\n",
    "Autoencoder tutorial: \n",
    "1. https://www.datacamp.com/community/tutorials/autoencoder-keras-tutorial\n",
    "2. https://www.kaggle.com/rvislaywade/visualizing-mnist-using-a-variational-autoencoder\n",
    "\n",
    "**Note: Post your work on the facebook using Colab to get an additional point**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
